{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Mistral 베이스 모델과 Instruct 모델 로드\n",
    "long_context_model_name = \"gradientai/Llama-3-8B-Instruct-262k\"  # 롱 컨텍\n",
    "base_model_name = \"kuotient/Meta-Llama-3-8B-Instruct\"\n",
    "target_model_name = \"beomi/Llama-3-Open-Ko-8B-Instruct-preview\"  # target 모델 이름 지정\n",
    "\n",
    "long_context_model = AutoModelForCausalLM.from_pretrained(long_context_model_name)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_name)\n",
    "target_model = AutoModelForCausalLM.from_pretrained(target_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weight_diff(base_weight, chat_weight):\n",
    "    return torch.abs(base_weight - chat_weight).mean().item()\n",
    "\n",
    "def calculate_layer_diffs(base_model, chat_model):\n",
    "    layer_diffs = []\n",
    "    for base_layer, chat_layer in zip(base_model.model.layers, chat_model.model.layers):\n",
    "        layer_diff = {\n",
    "            'input_layernorm': calculate_weight_diff(base_layer.input_layernorm.weight, chat_layer.input_layernorm.weight),\n",
    "            'mlp_down_proj': calculate_weight_diff(base_layer.mlp.down_proj.weight, chat_layer.mlp.down_proj.weight),\n",
    "            'mlp_gate_proj': calculate_weight_diff(base_layer.mlp.gate_proj.weight, chat_layer.mlp.gate_proj.weight),\n",
    "            'mlp_up_proj': calculate_weight_diff(base_layer.mlp.up_proj.weight, chat_layer.mlp.up_proj.weight),\n",
    "            'post_attention_layernorm': calculate_weight_diff(base_layer.post_attention_layernorm.weight, chat_layer.post_attention_layernorm.weight),\n",
    "            'self_attn_q_proj': calculate_weight_diff(base_layer.self_attn.q_proj.weight, chat_layer.self_attn.q_proj.weight),\n",
    "            'self_attn_k_proj': calculate_weight_diff(base_layer.self_attn.k_proj.weight, chat_layer.self_attn.k_proj.weight),\n",
    "            'self_attn_v_proj': calculate_weight_diff(base_layer.self_attn.v_proj.weight, chat_layer.self_attn.v_proj.weight),\n",
    "            'self_attn_o_proj': calculate_weight_diff(base_layer.self_attn.o_proj.weight, chat_layer.self_attn.o_proj.weight)\n",
    "        }\n",
    "        layer_diffs.append(layer_diff)\n",
    "    return layer_diffs\n",
    "\n",
    "def visualize_layer_diffs(layer_diffs):\n",
    "    num_layers = len(layer_diffs)\n",
    "    num_components = len(layer_diffs[0])\n",
    "    \n",
    "    fig, axs = plt.subplots(1, num_components, figsize=(24, 8))\n",
    "    fig.suptitle(f\"{base_model_name} <> {chat_model_name}\", fontsize=16)\n",
    "    \n",
    "    for i, component in enumerate(layer_diffs[0].keys()):\n",
    "        component_diffs = [[layer_diff[component]] for layer_diff in layer_diffs]\n",
    "        sns.heatmap(component_diffs, annot=True, fmt=\".6f\", cmap=\"YlGnBu\", ax=axs[i], cbar_kws={\"shrink\": 0.8})\n",
    "        axs[i].set_title(component)\n",
    "        axs[i].set_xlabel(\"Layer\")\n",
    "        axs[i].set_ylabel(\"Difference\")\n",
    "        axs[i].set_xticks([])\n",
    "        axs[i].set_yticks(range(num_layers))\n",
    "        axs[i].set_yticklabels(range(num_layers))\n",
    "        axs[i].invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 레이어별 가중치 차이 계산\n",
    "layer_diffs = calculate_layer_diffs(base_model, chat_model)\n",
    "\n",
    "# 가중치 차이 히트맵으로 시각화\n",
    "visualize_layer_diffs(layer_diffs)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
